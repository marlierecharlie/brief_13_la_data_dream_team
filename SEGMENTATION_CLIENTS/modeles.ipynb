{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21708cba",
   "metadata": {},
   "source": [
    "# Mise en place des modèles de clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7847cf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yellowbrick'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myellowbrick\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KElbowVisualizer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yellowbrick'"
     ]
    }
   ],
   "source": [
    "# Importations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8124aff9",
   "metadata": {},
   "source": [
    "Dans cette section, nous allons réaliser un modèle de clustering qui réalisera une segmentation des clients basée sur la méthode RFM (Récence, Fréquence, Montant). Cette segmentation sépare les clients selon trois critères : la date de la dernière commande passée, le nombre de commandes passées et le montant total dépensé par le client. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb36f1dd",
   "metadata": {},
   "source": [
    "## Choix des variables et analyses multivariées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491c4c92",
   "metadata": {},
   "source": [
    "Commençons par charger notre dataframe. Les colonnes qui vont nous être utiles ici sont les colonnes total_spent, last_order et order_frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c79a40-18e7-42a7-9046-1d24fa7a1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open(\"clean_data.pkl\", \"rb\"))\n",
    "cluster_df = df[[\"total_spent\", \"last_order\", \"orders_frequency\"]]\n",
    "print(cluster_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7f5c67-50e6-4572-b85d-fb167beebae1",
   "metadata": {},
   "source": [
    "D'abord, affichons une heatmap qui représente la matrice de corrélation de la dataframe afin de voir si certaines colonnes sont corrélées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ea5e6d-8157-421c-b048-81583be04a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cluster_df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a164a6-afbc-4294-a427-4136b983b50c",
   "metadata": {},
   "source": [
    "On constate que les corrélations entre nos différentes features sont faibles, voire nulles.\n",
    "\n",
    "Avant de réaliser un clustering sur nos données, il est important de mieux les comprendre. Pour cela, nous allons réaliser un nuage de points en trois dimensions de notre dataframe en utilisant la technique du PCA (Principal Component Analysis). Cela nous permettra de mieux identifier les différents clusters potentiels dans nos données.\n",
    "\n",
    "Pour bien voir l'intérêt du PCA, affichons d'abord nos données sans PCA :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45627c3-3963-42bc-b1d1-2f707b5448c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage du nuage de points sans PCA\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(27, 75)\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "x = cluster_df['total_spent']\n",
    "y = cluster_df['last_order']\n",
    "z = cluster_df['orders_frequency']\n",
    "\n",
    "ax.set_xlabel(\"total spent\")\n",
    "ax.set_ylabel(\"last order\")\n",
    "ax.set_zlabel(\"orders frequency\")\n",
    "\n",
    "ax.scatter(x, y, z)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad37a53-2837-4945-8811-dd78be696979",
   "metadata": {},
   "source": [
    "Et, maintenant, faisons la même chose en appliquant le PCA à nos données avant de les afficher :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bd362c-bbb6-4a30-bc5e-3fc6e8d11699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage du nuage de points avec PCA\n",
    "pca = PCA(n_components=3)\n",
    "standardized_cluster_df = StandardScaler().fit_transform(cluster_df)\n",
    "pca_cluster = pd.DataFrame(pca.fit_transform(standardized_cluster_df))\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(27, 75)\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "x = pca_cluster[0]\n",
    "y = pca_cluster[1]\n",
    "z = pca_cluster[2]\n",
    "\n",
    "ax.set_xlabel(\"total spent\")\n",
    "ax.set_ylabel(\"last order\")\n",
    "ax.set_zlabel(\"orders frequency\")\n",
    "\n",
    "ax.scatter(x, y, z)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8262a733-90b3-45ce-8079-2f834011c813",
   "metadata": {},
   "source": [
    "Bien qu'aucun de ces deux nuages de points en 3D ne soit très lisible, on peut tout de même plus facilement distinguer des groupes de points dans le second graphique (après PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b907bc5-0759-46ab-92a3-181a87e82e8f",
   "metadata": {},
   "source": [
    "Si l'on affiche maintenant la heatmap de nos données après y avoir appliqué le PCA, on constate qu'il n'y a plus de corrélation entre les différentes features. L'avantage du PCA est également d'éliminer ces colinéarités entre features, qui peuvent affecter la précision de notre modèle de clustering :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a940398-f41c-41b3-8926-3745b125070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pca_cluster.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf552f3-0941-4796-8481-4b192a325d9a",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d574ca-7281-45fd-9c85-59013f59589a",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bbd280-c8f0-424b-a931-bca826008910",
   "metadata": {},
   "source": [
    "Avant de commencer à créer nos modèles de clustering, une question se pose : combien de clusters faut-il identifier ? En effet, lorsque l'on crée un modèle, il faut lui donner le nombre de clusters à créer. Pour cela, nous pouvons utiliser la méthode elbow, qui identifie le nombre optimal de clusters. Au-delà de ce nombre, on court le risque de créer trop de clusters, qui seront trop restreints individuellement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c93e9b-0d72-49dc-a19d-001e466d6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=(1,20))\n",
    "\n",
    "visualizer.fit(pca_cluster)       \n",
    "visualizer.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d018e38-5c89-4a63-bf68-aa9da3e8dcc7",
   "metadata": {},
   "source": [
    "La librairie Yellowbrick, que nous avons utilisée pour générer ce graphique, nous montre le nombre de clusters optimal, 5 dans ce cas. Maintenant que nous connaissons le nombre de clusters à utiliser, nous pouvons générer notre modèle de clustering à l'aide de la méthode des k-means :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb425d-f680-445a-8231-4ec9ba475cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = KMeans(n_clusters=5).fit(pca_cluster.astype(float))\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(27, 75)\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "x = pca_cluster[0]\n",
    "y = pca_cluster[1]\n",
    "z = pca_cluster[2]\n",
    "\n",
    "ax.set_xlabel(\"total spent\")\n",
    "ax.set_ylabel(\"last order\")\n",
    "ax.set_zlabel(\"orders frequency\")\n",
    "\n",
    "ax.scatter(x, y, z, c=clusters.labels_.astype(float))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab55f515-8fc3-41fd-8a4f-61ad9eb5e160",
   "metadata": {},
   "source": [
    "Le nuage de points 3D obtenu n'est pas très lisible. Un bon moyen de mieux visualiser les différences entre chaque cluster obtenu est de dessiner un graphique en toile d'araignée où chaque axe correspond à une feature :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe52c90-733d-40de-9755-c4f1e30dfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_cluster_df = pd.DataFrame(cluster_df)\n",
    "k_means_cluster_df[\"cluster\"] = clusters.labels_.astype(int)\n",
    "# On calcule la moyenne de chaque feature à l'intérieur de chaque catégorie\n",
    "categories_df = k_means_cluster_df.groupby([\"cluster\"]).mean()\n",
    "print(categories_df)\n",
    "# On normalise ensuite toutes les valeurs de la dataframe pour avoir une\n",
    "# échelle cohérente dans notre graphique\n",
    "categories_df = (categories_df-categories_df.mean())/categories_df.std()\n",
    "categories_df.reset_index(inplace=True)\n",
    "print(categories_df)\n",
    "melted_df = pd.melt(categories_df, id_vars=['cluster'], var_name='feature', value_name='data',\n",
    "             value_vars=['total_spent', 'last_order', 'orders_frequency'])\n",
    "\n",
    "fig = px.line_polar(melted_df, r=\"data\", theta=\"feature\", color=\"cluster\", line_close=True)\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f023960-665c-42fb-8581-009d1628831e",
   "metadata": {},
   "source": [
    "Les tableaux et le graphique ci-dessus nous permettent de mettre en évidence plusieurs éléments : \n",
    "- les clients qui font partie du groupe 2 dépensent nettement plus d'argent que les autres groupes (environ 1200 dollars au total par client en moyenne). Une attention toute particulière devrait donc être prêtée aux clients assignés à ce groupe par le modèle\n",
    "- Les clients du groupe 4 présentent aussi un intérêt. Ils passent commande beaucoup plus fréquemment que les autres clients et dépensent aussi beaucoup globalement (730 dollars en moyenne)\n",
    "- Les clients des groupes 0, 1 et 3 ne présentent qu'un intérêt limité dans la mesure où ils dépensent relativement peu comparé aux autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a04606e-b943-4f75-8224-63eef837e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performances du modèle :\n",
    "labels = clusters.labels_\n",
    "metrics.silhouette_score(pca_cluster, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd45f7-e089-4c75-a51b-3ba854441c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification ascendante hiérarchique (CAH)  (à venir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550d0f1-e2bb-4022-9e98-c58cb5b0455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dbscan (à venir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76486f49-ff86-4605-85ee-6d329fa91140",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optics (à venir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb84fc6-795d-4da4-a350-fe4bf5dc5923",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
