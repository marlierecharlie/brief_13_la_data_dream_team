{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8ca29da",
   "metadata": {},
   "source": [
    "# Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f696dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import haversine as hs # Un module qui permet de calculer la distance entre deux points en fonction de leurs coordonnées GPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687ae662",
   "metadata": {},
   "source": [
    "## Découverte des datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede289c2-6ae4-47ee-bc0b-0f17abc31944",
   "metadata": {},
   "source": [
    "Pour commencer, découvrons tous les datasets afin de nous familiariser avec leur contenu et de définir quelles données pourront potentiellement nous être utiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aa49e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               99441 non-null  object\n",
      " 1   customer_unique_id        99441 non-null  object\n",
      " 2   customer_zip_code_prefix  99441 non-null  int64 \n",
      " 3   customer_city             99441 non-null  object\n",
      " 4   customer_state            99441 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "                        customer_id                customer_unique_id  \\\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
      "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
      "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
      "\n",
      "   customer_zip_code_prefix          customer_city customer_state  \n",
      "0                     14409                 franca             SP  \n",
      "1                      9790  sao bernardo do campo             SP  \n",
      "2                      1151              sao paulo             SP  \n",
      "3                      8775        mogi das cruzes             SP  \n",
      "4                     13056               campinas             SP  \n"
     ]
    }
   ],
   "source": [
    "customers_df = pd.read_csv(\"data/olist_customers_dataset.csv\")\n",
    "print(customers_df.info())\n",
    "print(customers_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c845aad-64ab-4092-a247-95fe9acfb609",
   "metadata": {},
   "source": [
    "On remarque que ce dataset pourrait nous être utile, dans la mesure où il contient des informations sur les clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f741f56-9d67-478c-b5ea-bbaffc557f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000163 entries, 0 to 1000162\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count    Dtype  \n",
      "---  ------                       --------------    -----  \n",
      " 0   geolocation_zip_code_prefix  1000163 non-null  int64  \n",
      " 1   geolocation_lat              1000163 non-null  float64\n",
      " 2   geolocation_lng              1000163 non-null  float64\n",
      " 3   geolocation_city             1000163 non-null  object \n",
      " 4   geolocation_state            1000163 non-null  object \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 38.2+ MB\n",
      "None\n",
      "   geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
      "0                         1037       -23.545621       -46.639292   \n",
      "1                         1046       -23.546081       -46.644820   \n",
      "2                         1046       -23.546129       -46.642951   \n",
      "3                         1041       -23.544392       -46.639499   \n",
      "4                         1035       -23.541578       -46.641607   \n",
      "\n",
      "  geolocation_city geolocation_state  \n",
      "0        sao paulo                SP  \n",
      "1        sao paulo                SP  \n",
      "2        sao paulo                SP  \n",
      "3        sao paulo                SP  \n",
      "4        sao paulo                SP  \n"
     ]
    }
   ],
   "source": [
    "geolocation_df = pd.read_csv(\"data/olist_geolocation_dataset.csv\")\n",
    "print(geolocation_df.info())\n",
    "print(geolocation_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ee694-321d-46a8-a31b-cb9d94156f54",
   "metadata": {},
   "source": [
    "Même si l'intérêt de ce dataset semble plus limité pour établir une segmentation des clients, on pourrait tout à fait imaginer que la géolocalisation des clients soit un facteur qui serait à l'origine de différences régionales dans le comportement des clients. Par exemple, on pourrait tout à fait imaginer un cas où les habitants d'une région commanderaient plus ou moins certains produits pour des raisons culturelles ou religieuses, par exemple. Dans ce cas, la géolocalisation pourrait être une information précieuse : c'est pourquoi nous allons  aussi utiliser ce dataset dans notre analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51748f79-5c05-40bc-8fb0-7003ae9bc324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   order_id             112650 non-null  object \n",
      " 1   order_item_id        112650 non-null  int64  \n",
      " 2   product_id           112650 non-null  object \n",
      " 3   seller_id            112650 non-null  object \n",
      " 4   shipping_limit_date  112650 non-null  object \n",
      " 5   price                112650 non-null  float64\n",
      " 6   freight_value        112650 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 6.0+ MB\n",
      "None\n",
      "                           order_id  order_item_id  \\\n",
      "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
      "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
      "2  000229ec398224ef6ca0657da4fc703e              1   \n",
      "3  00024acbcdf0a6daa1e931b038114c75              1   \n",
      "4  00042b26cf59d7ce69dfabb4e55b4fd9              1   \n",
      "\n",
      "                         product_id                         seller_id  \\\n",
      "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
      "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
      "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
      "3  7634da152a4610f1595efa32f14722fc  9d7a1d34a5052409006425275ba1c2b4   \n",
      "4  ac6c3623068f30de03045865e4e10089  df560393f3a51e74553ab94004ba5c87   \n",
      "\n",
      "   shipping_limit_date   price  freight_value  \n",
      "0  2017-09-19 09:45:35   58.90          13.29  \n",
      "1  2017-05-03 11:05:13  239.90          19.93  \n",
      "2  2018-01-18 14:48:30  199.00          17.87  \n",
      "3  2018-08-15 10:10:18   12.99          12.79  \n",
      "4  2017-02-13 13:57:51  199.90          18.14  \n"
     ]
    }
   ],
   "source": [
    "order_items_df = pd.read_csv(\"data/olist_order_items_dataset.csv\")\n",
    "print(order_items_df.info())\n",
    "print(order_items_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee970c6-f90b-496e-a0ab-a6c283ce0f40",
   "metadata": {},
   "source": [
    "Les produits commandés ainsi que leur prix sont des informations cruciales pour comprendre les clients : nous allons donc utiliser ce dataset dans nos analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd001875-3036-4a6c-8baa-c7cb44ef9f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103886 entries, 0 to 103885\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   order_id              103886 non-null  object \n",
      " 1   payment_sequential    103886 non-null  int64  \n",
      " 2   payment_type          103886 non-null  object \n",
      " 3   payment_installments  103886 non-null  int64  \n",
      " 4   payment_value         103886 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 4.0+ MB\n",
      "None\n",
      "                           order_id  payment_sequential payment_type  \\\n",
      "0  b81ef226f3fe1789b1e8b2acac839d17                   1  credit_card   \n",
      "1  a9810da82917af2d9aefd1278f1dcfa0                   1  credit_card   \n",
      "2  25e8ea4e93396b6fa0d3dd708e76c1bd                   1  credit_card   \n",
      "3  ba78997921bbcdc1373bb41e913ab953                   1  credit_card   \n",
      "4  42fdf880ba16b47b59251dd489d4441a                   1  credit_card   \n",
      "\n",
      "   payment_installments  payment_value  \n",
      "0                     8          99.33  \n",
      "1                     1          24.39  \n",
      "2                     1          65.71  \n",
      "3                     8         107.78  \n",
      "4                     2         128.45  \n"
     ]
    }
   ],
   "source": [
    "order_payments_df = pd.read_csv(\"data/olist_order_payments_dataset.csv\")\n",
    "print(order_payments_df.info())\n",
    "print(order_payments_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c091c8-84ad-4a7c-9b20-526a69514f66",
   "metadata": {},
   "source": [
    "Ce dataset pourrait nous apprendre des choses sur les habitudes de paiement des clients (méthode de paiement, paiement en une ou plusieurs fois...). Gardons-le pour notre analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "762a765c-4c51-4c47-a509-eb9dec4bba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99224 entries, 0 to 99223\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   review_id                99224 non-null  object\n",
      " 1   order_id                 99224 non-null  object\n",
      " 2   review_score             99224 non-null  int64 \n",
      " 3   review_comment_title     11568 non-null  object\n",
      " 4   review_comment_message   40977 non-null  object\n",
      " 5   review_creation_date     99224 non-null  object\n",
      " 6   review_answer_timestamp  99224 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.3+ MB\n",
      "None\n",
      "                          review_id                          order_id  \\\n",
      "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
      "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
      "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
      "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
      "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
      "\n",
      "   review_score review_comment_title  \\\n",
      "0             4                  NaN   \n",
      "1             5                  NaN   \n",
      "2             5                  NaN   \n",
      "3             5                  NaN   \n",
      "4             5                  NaN   \n",
      "\n",
      "                              review_comment_message review_creation_date  \\\n",
      "0                                                NaN  2018-01-18 00:00:00   \n",
      "1                                                NaN  2018-03-10 00:00:00   \n",
      "2                                                NaN  2018-02-17 00:00:00   \n",
      "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
      "4  Parabéns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
      "\n",
      "  review_answer_timestamp  \n",
      "0     2018-01-18 21:46:59  \n",
      "1     2018-03-11 03:05:13  \n",
      "2     2018-02-18 14:36:24  \n",
      "3     2017-04-21 22:02:06  \n",
      "4     2018-03-02 10:26:53  \n"
     ]
    }
   ],
   "source": [
    "order_reviews_df = pd.read_csv(\"data/olist_order_reviews_dataset.csv\")\n",
    "print(order_reviews_df.info())\n",
    "print(order_reviews_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4617ef19-8330-48ba-b162-15702741fd36",
   "metadata": {},
   "source": [
    "Ici, le dataset donne des informations sur les éventuels commentaires laissés par des clients. L'intérêt pourrait être de segmenter les clients en prenant en compte le fait qu'ils laissent des commentaires ou non, voire de convertir le texte des messages en vecteurs pour les utiliser dans notre modèle de segmentation. Il paraît donc judicieux de garder ces données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d866c835-fdec-4077-8a00-d168f04380b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_id                       99441 non-null  object\n",
      " 1   customer_id                    99441 non-null  object\n",
      " 2   order_status                   99441 non-null  object\n",
      " 3   order_purchase_timestamp       99441 non-null  object\n",
      " 4   order_approved_at              99281 non-null  object\n",
      " 5   order_delivered_carrier_date   97658 non-null  object\n",
      " 6   order_delivered_customer_date  96476 non-null  object\n",
      " 7   order_estimated_delivery_date  99441 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.1+ MB\n",
      "None\n",
      "                           order_id                       customer_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
      "\n",
      "  order_status order_purchase_timestamp    order_approved_at  \\\n",
      "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
      "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
      "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
      "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
      "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
      "\n",
      "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
      "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
      "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
      "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
      "\n",
      "  order_estimated_delivery_date  \n",
      "0           2017-10-18 00:00:00  \n",
      "1           2018-08-13 00:00:00  \n",
      "2           2018-09-04 00:00:00  \n",
      "3           2017-12-15 00:00:00  \n",
      "4           2018-02-26 00:00:00  \n"
     ]
    }
   ],
   "source": [
    "orders_df = pd.read_csv(\"data/olist_orders_dataset.csv\")\n",
    "print(orders_df.info())\n",
    "print(orders_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53374c6-96b2-4caf-8466-40e126374e23",
   "metadata": {},
   "source": [
    "Ce dataset nous permettra de faire des fusions entre les différents datasets qui nous intéressent, via les colonnes order_id et customer_id. Les données décrivant les délais de livraison nous permettront aussi d'étudier la temporalité des commandes et pourront peut-être être utiles pour définir plusieurs catégories de clients (on pourrait tout à fait envisager que certains clients veulent être livrés rapidement, par exemple, ce qui aurait une influence sur la stratégie marketing à adopter à leur égard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f0e7794-e72a-4f5d-b034-22156a52522a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32341 non-null  object \n",
      " 2   product_name_lenght         32341 non-null  float64\n",
      " 3   product_description_lenght  32341 non-null  float64\n",
      " 4   product_photos_qty          32341 non-null  float64\n",
      " 5   product_weight_g            32949 non-null  float64\n",
      " 6   product_length_cm           32949 non-null  float64\n",
      " 7   product_height_cm           32949 non-null  float64\n",
      " 8   product_width_cm            32949 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "                         product_id  product_category_name  \\\n",
      "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria   \n",
      "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes   \n",
      "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer   \n",
      "3  cef67bcfe19066a932b7673e239eb23d                  bebes   \n",
      "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas   \n",
      "\n",
      "   product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
      "0                 40.0                       287.0                 1.0   \n",
      "1                 44.0                       276.0                 1.0   \n",
      "2                 46.0                       250.0                 1.0   \n",
      "3                 27.0                       261.0                 1.0   \n",
      "4                 37.0                       402.0                 4.0   \n",
      "\n",
      "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
      "0             225.0               16.0               10.0              14.0  \n",
      "1            1000.0               30.0               18.0              20.0  \n",
      "2             154.0               18.0                9.0              15.0  \n",
      "3             371.0               26.0                4.0              26.0  \n",
      "4             625.0               20.0               17.0              13.0  \n"
     ]
    }
   ],
   "source": [
    "products_df = pd.read_csv(\"data/olist_products_dataset.csv\")\n",
    "print(products_df.info())\n",
    "print(products_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56763e87-534f-4d4a-980d-edc7f2df23fb",
   "metadata": {},
   "source": [
    "Ici, c'est surtout la colonne product_category_name qui va nous intéresser. En effet, tandis que différents clients achètent différents types de produits, on peine à comprendre comment les dimensions ou le poids des produits pourraient avoir une influence sur le comportement des clients !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b84dc7c-272d-44f1-8c0d-f4fbb8aba5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3095 entries, 0 to 3094\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   seller_id               3095 non-null   object\n",
      " 1   seller_zip_code_prefix  3095 non-null   int64 \n",
      " 2   seller_city             3095 non-null   object\n",
      " 3   seller_state            3095 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 96.8+ KB\n",
      "None\n",
      "                          seller_id  seller_zip_code_prefix  \\\n",
      "0  3442f8959a84dea7ee197c632cb2df15                   13023   \n",
      "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844   \n",
      "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031   \n",
      "3  c0f3eea2e14555b6faeea3dd58c1b1c3                    4195   \n",
      "4  51a04a8a6bdcb23deccc82b0b80742cf                   12914   \n",
      "\n",
      "         seller_city seller_state  \n",
      "0           campinas           SP  \n",
      "1         mogi guacu           SP  \n",
      "2     rio de janeiro           RJ  \n",
      "3          sao paulo           SP  \n",
      "4  braganca paulista           SP  \n"
     ]
    }
   ],
   "source": [
    "sellers_df = pd.read_csv(\"data/olist_sellers_dataset.csv\")\n",
    "print(sellers_df.info())\n",
    "print(sellers_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782de948-d4f0-4d13-8b13-55cec7f5ac1d",
   "metadata": {},
   "source": [
    "Ici, la colonne seller_zip_code_prefix pourrait nous être utile. De nos jours, de plus en plus de clients cherchent à consommer local. Il s'ensuit que connaître la localisation du vendeur et celle de l'acheteur pourrait peut-être nous permettre de calculer la distance, ce qui aurait son importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b15c107-913b-4960-a5d1-1bb3c8a76cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71 entries, 0 to 70\n",
      "Data columns (total 2 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   product_category_name          71 non-null     object\n",
      " 1   product_category_name_english  71 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ KB\n",
      "None\n",
      "    product_category_name product_category_name_english\n",
      "0            beleza_saude                 health_beauty\n",
      "1  informatica_acessorios         computers_accessories\n",
      "2              automotivo                          auto\n",
      "3         cama_mesa_banho                bed_bath_table\n",
      "4        moveis_decoracao               furniture_decor\n"
     ]
    }
   ],
   "source": [
    "product_category_name_translation_df = pd.read_csv(\"data/product_category_name_translation.csv\")\n",
    "print(product_category_name_translation_df.info())\n",
    "print(product_category_name_translation_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03007d4b-c38f-4fb2-abff-8d7779c7b30c",
   "metadata": {},
   "source": [
    "Cette table nous servira à remplacer les noms des catégories en portugais par ceux en anglais. Dans la mesure où personne ne parle portugais dans l'équipe, cela semble être un bon moyen de mieux comprendre les résultats du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da74681-b189-421f-aa7c-b06c50206994",
   "metadata": {},
   "source": [
    "## Création d'une dataframe unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d48328-370f-4500-ac60-f4ba5e60b89c",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons créer une unique dataframe qui contient toutes les informations qui peuvent potentiellement nous intéresser. De là, nous pourrons ensuite facilement créer d'autres colonnes qui nous intéressent à partir d'autres données (e.g. créer une colonne \"distance moyenne entre le client et les vendeurs\") et réaliser des analyses pour mieux comprendre les relations entre les données. La dataframe ainsi obtenue sera sauvegardée avec Pickle afin de ne pas avoir à exécuter tout le code du notebook à chaque fois que l'on souhaite accéder à la dataframe.\n",
    "\n",
    "Cette dataframe unique devra référencer les clients (une ligne = un client). Nous allons donc prendre comme base la dataframe customers_df. Dans un premier temps, fusionnons customers_df et geolocation_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21152871-75de-4f91-a267-11994619dd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99441 entries, 0 to 99440\n",
      "Data columns (total 10 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   customer_id                  99441 non-null  object \n",
      " 1   customer_unique_id           99441 non-null  object \n",
      " 2   customer_zip_code_prefix     99441 non-null  int64  \n",
      " 3   customer_city                99441 non-null  object \n",
      " 4   customer_state               99441 non-null  object \n",
      " 5   geolocation_zip_code_prefix  99163 non-null  float64\n",
      " 6   geolocation_lat              99163 non-null  float64\n",
      " 7   geolocation_lng              99163 non-null  float64\n",
      " 8   geolocation_city             99163 non-null  object \n",
      " 9   geolocation_state            99163 non-null  object \n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 8.3+ MB\n",
      "None\n",
      "                        customer_id                customer_unique_id  \\\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
      "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
      "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
      "\n",
      "   customer_zip_code_prefix          customer_city customer_state  \\\n",
      "0                     14409                 franca             SP   \n",
      "1                      9790  sao bernardo do campo             SP   \n",
      "2                      1151              sao paulo             SP   \n",
      "3                      8775        mogi das cruzes             SP   \n",
      "4                     13056               campinas             SP   \n",
      "\n",
      "   geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
      "0                      14409.0       -20.509897       -47.397866   \n",
      "1                       9790.0       -23.726853       -46.545746   \n",
      "2                       1151.0       -23.527788       -46.660310   \n",
      "3                       8775.0       -23.496930       -46.185352   \n",
      "4                      13056.0       -22.987222       -47.151073   \n",
      "\n",
      "        geolocation_city geolocation_state  \n",
      "0                 franca                SP  \n",
      "1  sao bernardo do campo                SP  \n",
      "2              sao paulo                SP  \n",
      "3        mogi das cruzes                SP  \n",
      "4               campinas                SP  \n"
     ]
    }
   ],
   "source": [
    "unique_df = customers_df\n",
    "# Dans geolocation_df, le même code postal peut avoir plusieurs coordonnées. On commence\n",
    "# donc par supprimer tous les doublons en se basant sur les codes zip pour que chaque\n",
    "# code corresponde à une seule paire de coordonnées.\n",
    "geolocation_df.drop_duplicates(subset=[\"geolocation_zip_code_prefix\"], inplace=True)\n",
    "unique_df = unique_df.merge(geolocation_df, how=\"left\", left_on=\"customer_zip_code_prefix\", right_on=\"geolocation_zip_code_prefix\")\n",
    "print(unique_df.info())\n",
    "print(unique_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66baeb5d-a5f2-4423-83ba-f0f167bf6e98",
   "metadata": {},
   "source": [
    "On pensera aussi à supprimer les colonnes en doublon et celles qui ne nous intéressent pas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3e526dc-5440-4b30-a9af-946559b14d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99441 entries, 0 to 99440\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   customer_id               99441 non-null  object \n",
      " 1   customer_unique_id        99441 non-null  object \n",
      " 2   customer_zip_code_prefix  99441 non-null  int64  \n",
      " 3   customer_city             99441 non-null  object \n",
      " 4   customer_state            99441 non-null  object \n",
      " 5   geolocation_lat           99163 non-null  float64\n",
      " 6   geolocation_lng           99163 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 6.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "unique_df.drop(columns=[\"geolocation_zip_code_prefix\", \"geolocation_city\", \"geolocation_state\"], inplace=True)\n",
    "print(unique_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0daf2f-b91b-474d-bafb-0dae11ba1f01",
   "metadata": {},
   "source": [
    "Au passage, on renomme les colonnes pour simplifier un peu :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68583da2-9072-419e-9a4a-572feaadf7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99441 entries, 0 to 99440\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   id         99441 non-null  object \n",
      " 1   unique_id  99441 non-null  object \n",
      " 2   zip        99441 non-null  int64  \n",
      " 3   city       99441 non-null  object \n",
      " 4   state      99441 non-null  object \n",
      " 5   lat        99163 non-null  float64\n",
      " 6   lng        99163 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 6.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "names_mapping = {\n",
    "                \"customer_id\": \"id\",\n",
    "                \"customer_unique_id\": \"unique_id\",\n",
    "                \"customer_zip_code_prefix\": \"zip\",\n",
    "                \"customer_city\": \"city\",\n",
    "                \"customer_state\": \"state\",\n",
    "                \"geolocation_lat\": \"lat\",\n",
    "                \"geolocation_lng\": \"lng\"\n",
    "                }\n",
    "                 \n",
    "unique_df.rename(columns=names_mapping, inplace=True)\n",
    "print(unique_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7a6f9f-58d3-4fb9-a7c8-a2f01c1dbbcc",
   "metadata": {},
   "source": [
    "Notre prochain objectif sera d'ajouter les colonnes suivantes à notre dataframe :\n",
    "- \"total_spent\" : le montant total dépensé par le client, toutes commandes confondues\n",
    "- \"avg_spent\" : le montant de commande moyen du client\n",
    "- \"avg_installments\" : le nombre moyen de paiements par commande pour le client\n",
    "- \"avg_review\" : la note moyenne donnée par le client après ses commandes\n",
    "- \"favorite_category\" : la catégorie de produits la plus achetée par le client (on prendra le nom de la catégorie en anglais).\n",
    "- \"distance_to_seller\" : la distance entre la ville où se trouve le vendeur et celle où se trouve le client.\n",
    "\n",
    "\n",
    "Après réflexion, nous ne nous occuperons pas des données qui concernent les dates et délais de livraison pour l'instant afin de nous concentrer sur les colonnes qui paraissent les plus pertinentes pour segmenter les clients. Par ailleurs, les messages contenus dans les reviews ne seront pas utilisés, du moins dans un premier temps. Il faudrait pour cela les vectoriser, ce qui alourdirait considérablement notre futur modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82ba32d-e301-496e-aaa7-3c36e61bf590",
   "metadata": {},
   "source": [
    "### Ajout de la colonne avg_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eb9aea-f1cd-49de-a86b-010fd91626cc",
   "metadata": {},
   "source": [
    "On commence par ajouter une colonne contenant l'id du client à la dataframe order_reviews_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f7de928-44a6-4e84-9f9f-1cca89c9725b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99224 entries, 0 to 99223\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   review_id               99224 non-null  object\n",
      " 1   order_id                99224 non-null  object\n",
      " 2   review_score            99224 non-null  int64 \n",
      " 3   review_comment_title    11568 non-null  object\n",
      " 4   review_comment_message  40977 non-null  object\n",
      " 5   customer_id             99224 non-null  object\n",
      " 6   customer_unique_id      99224 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 6.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Création d'une table intermediate_df qui reprend les données de order_reviews_df \n",
    "# et y ajoute une colonne qui contient l'id unique du client qui a passé la commande\n",
    "intermediate_df = order_reviews_df.merge(orders_df, how=\"left\", on=\"order_id\")\n",
    "intermediate_df = intermediate_df.drop(columns=[\"review_creation_date\", \n",
    "                                                \"review_answer_timestamp\",\n",
    "                                                \"order_status\",\n",
    "                                                \"order_purchase_timestamp\",\n",
    "                                                \"order_approved_at\",\n",
    "                                                \"order_delivered_carrier_date\",\n",
    "                                                \"order_delivered_customer_date\",\n",
    "                                                \"order_estimated_delivery_date\"])\n",
    "intermediate_df = intermediate_df.merge(customers_df, how=\"left\", on=\"customer_id\")\n",
    "intermediate_df.drop(columns=[\"customer_zip_code_prefix\",\n",
    "                              \"customer_city\",\n",
    "                              \"customer_state\"], inplace= True)\n",
    "\n",
    "print(intermediate_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916115e7-cc50-4278-a52d-4202ccd4d671",
   "metadata": {},
   "source": [
    "Ensuite, on crée une colonne avg_review qui contient la note moyenne donnée par chaque client et on l'ajoute à notre dataframe unique_df :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d58b058b-8da7-49c6-ad49-fe2c486d39eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          99441 non-null  object \n",
      " 1   unique_id   99441 non-null  object \n",
      " 2   zip         99441 non-null  int64  \n",
      " 3   city        99441 non-null  object \n",
      " 4   state       99441 non-null  object \n",
      " 5   lat         99163 non-null  float64\n",
      " 6   lng         99163 non-null  float64\n",
      " 7   avg_review  98716 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 6.8+ MB\n",
      "None\n",
      "                                 id                         unique_id    zip  \\\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0  14409   \n",
      "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   9790   \n",
      "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   1151   \n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   8775   \n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066  13056   \n",
      "\n",
      "                    city state        lat        lng  avg_review  \n",
      "0                 franca    SP -20.509897 -47.397866         4.0  \n",
      "1  sao bernardo do campo    SP -23.726853 -46.545746         5.0  \n",
      "2              sao paulo    SP -23.527788 -46.660310         5.0  \n",
      "3        mogi das cruzes    SP -23.496930 -46.185352         5.0  \n",
      "4               campinas    SP -22.987222 -47.151073         5.0  \n"
     ]
    }
   ],
   "source": [
    "reviews_df = intermediate_df.groupby([\"customer_unique_id\"]).mean(numeric_only=True)\n",
    "reviews_df.rename(columns={\"review_score\": \"avg_review\"}, inplace=True)\n",
    "unique_df = unique_df.merge(how=\"left\", right=reviews_df, left_on=\"unique_id\", right_on=\"customer_unique_id\")\n",
    "print(unique_df.info())\n",
    "print(unique_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c4a079-0101-4b1f-a4e9-59c68d34ad2f",
   "metadata": {},
   "source": [
    "### Ajout des colonnes total_spent et avg_spent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb18fd76-869f-405f-b087-389131bffd08",
   "metadata": {},
   "source": [
    "Pour récupérer ces informations, on commencera par créer une dataframe qui répertorie tous les articles vendus avec les id du client et de la commande, le prix de l'article et sa catégorie. On se basera sur la dataframe order_items_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd30703b-92b9-488f-a8ed-dffdbc9433de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 112650 entries, 0 to 112649\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   order_id                  112650 non-null  object \n",
      " 1   order_item_id             112650 non-null  int64  \n",
      " 2   product_id                112650 non-null  object \n",
      " 3   seller_id                 112650 non-null  object \n",
      " 4   price                     112650 non-null  float64\n",
      " 5   customer_id               112650 non-null  object \n",
      " 6   customer_unique_id        112650 non-null  object \n",
      " 7   customer_zip_code_prefix  112650 non-null  int64  \n",
      " 8   customer_city             112650 non-null  object \n",
      " 9   customer_state            112650 non-null  object \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 9.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sold_items_df = order_items_df.copy()\n",
    "sold_items_df.drop(columns=[\"shipping_limit_date\", \"freight_value\"], inplace=True)\n",
    "sold_items_df = sold_items_df.merge(how=\"left\", right=orders_df, on=\"order_id\")\n",
    "sold_items_df.drop(columns=[\"order_status\", \n",
    "                            \"order_purchase_timestamp\",\n",
    "                            \"order_approved_at\",\n",
    "                            \"order_delivered_carrier_date\",\n",
    "                            \"order_delivered_customer_date\",\n",
    "                            \"order_estimated_delivery_date\"], inplace=True)\n",
    "sold_items_df = sold_items_df.merge(how=\"left\", right=customers_df, left_on=\"customer_id\", right_on=\"customer_id\")\n",
    "\n",
    "print(sold_items_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225ed46-a074-4a40-b5d1-4aac47c063e4",
   "metadata": {},
   "source": [
    "On ajoute ensuite les colonnes qui nous intéressent (total_spent et avg_spent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "773b6262-adc0-41af-891c-c1eda1d85bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 95420 entries, 0000366f3b9a7992bf8c76cfdf3221e2 to ffffd2657e2aad2907e67c3e9daecbeb\n",
      "Data columns (total 3 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   order_item_id             95420 non-null  int64  \n",
      " 1   price                     95420 non-null  float64\n",
      " 2   customer_zip_code_prefix  95420 non-null  int64  \n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 2.9+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 95420 entries, 0000366f3b9a7992bf8c76cfdf3221e2 to ffffd2657e2aad2907e67c3e9daecbeb\n",
      "Data columns (total 3 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   order_item_id             95420 non-null  float64\n",
      " 1   price                     95420 non-null  float64\n",
      " 2   customer_zip_code_prefix  95420 non-null  float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 2.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "total_spent = sold_items_df.groupby([\"customer_unique_id\"]).sum(numeric_only=True)\n",
    "print(total_spent.info())\n",
    "avg_spent = sold_items_df.groupby([\"customer_unique_id\"]).mean(numeric_only=True)\n",
    "print(avg_spent.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e71d8-f9e1-4c0f-be0d-16b3b954f55d",
   "metadata": {},
   "source": [
    "On ajoute les deux colonnes nouvellement créées à notre dataframe unique_df :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfec5483-4fc4-4e60-a113-e68030146b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99441 entries, 0 to 99440\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           99441 non-null  object \n",
      " 1   unique_id    99441 non-null  object \n",
      " 2   zip          99441 non-null  int64  \n",
      " 3   city         99441 non-null  object \n",
      " 4   state        99441 non-null  object \n",
      " 5   lat          99163 non-null  float64\n",
      " 6   lng          99163 non-null  float64\n",
      " 7   avg_review   98716 non-null  float64\n",
      " 8   total_spent  98756 non-null  float64\n",
      " 9   avg_spent    98756 non-null  float64\n",
      "dtypes: float64(5), int64(1), object(4)\n",
      "memory usage: 8.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "total_spent.rename(columns={\"price\": \"total_spent\"}, inplace=True)\n",
    "unique_df = unique_df.merge(how=\"left\", right=total_spent[\"total_spent\"], left_on=\"unique_id\", right_index=True)\n",
    "avg_spent.rename(columns={\"price\": \"avg_spent\"}, inplace=True)\n",
    "unique_df = unique_df.merge(how=\"left\", right=avg_spent[\"avg_spent\"], left_on=\"unique_id\", right_index=True)\n",
    "print(unique_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99568506-b2ee-4fd8-b4d5-5eb0f45af58e",
   "metadata": {},
   "source": [
    "### Ajout des colonnes avg_installments, favorite_category et distance_to_seller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b78b0d9-32e0-438e-8273-73bfdfc353b8",
   "metadata": {},
   "source": [
    "On commence par ajouter à notre dataframe sold_items_df les informations concernant les paiements, les catégories de produits et les vendeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea4363cf-a80a-4dfe-a63e-9b180850cf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 117604 entries, 0 to 117603\n",
      "Data columns (total 15 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   order_id                  117604 non-null  object \n",
      " 1   order_item_id             117604 non-null  int64  \n",
      " 2   product_id                117604 non-null  object \n",
      " 3   seller_id                 117604 non-null  object \n",
      " 4   price                     117604 non-null  float64\n",
      " 5   customer_id               117604 non-null  object \n",
      " 6   customer_unique_id        117604 non-null  object \n",
      " 7   customer_zip_code_prefix  117604 non-null  int64  \n",
      " 8   customer_city             117604 non-null  object \n",
      " 9   customer_state            117604 non-null  object \n",
      " 10  product_category_name     115906 non-null  object \n",
      " 11  seller_zip_code_prefix    117604 non-null  int64  \n",
      " 12  seller_city               117604 non-null  object \n",
      " 13  seller_state              117604 non-null  object \n",
      " 14  payment_installments      117601 non-null  float64\n",
      "dtypes: float64(2), int64(3), object(10)\n",
      "memory usage: 14.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sold_items_df = sold_items_df.merge(how=\"left\", right=products_df, on=\"product_id\")\n",
    "sold_items_df.drop(columns=[\"product_name_lenght\",\n",
    "                            \"product_description_lenght\",\n",
    "                            \"product_photos_qty\",\n",
    "                            \"product_weight_g\",\n",
    "                            \"product_length_cm\",\n",
    "                            \"product_height_cm\",\n",
    "                            \"product_width_cm\"], inplace=True)\n",
    "\n",
    "sold_items_df = sold_items_df.merge(how=\"left\", right=sellers_df, on=\"seller_id\")\n",
    "sold_items_df = sold_items_df.merge(how=\"left\", right=order_payments_df, on=\"order_id\")\n",
    "sold_items_df.drop(columns=[\"payment_sequential\", \"payment_type\", \"payment_value\"], inplace=True)\n",
    "\n",
    "\n",
    "print(sold_items_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e8da33-7c99-462b-8e3e-b119001d339f",
   "metadata": {},
   "source": [
    "À partir de cette dataframe, on va générer trois nouvelles dataframes qui contiennent respectivement la catégorie de produits préférée de chaque client, sa distance moyenne avec les vendeurs où il achète ses articles, et le nombre de paiements moyen qu'il réalise lors de ses achats. Dans la foulée, on ajoutera ces données à notre dataframe unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcd32dbb-4a9d-49ee-8ff9-8e105f67c4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99441 entries, 0 to 99440\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                99441 non-null  object \n",
      " 1   unique_id         99441 non-null  object \n",
      " 2   zip               99441 non-null  int64  \n",
      " 3   city              99441 non-null  object \n",
      " 4   state             99441 non-null  object \n",
      " 5   lat               99163 non-null  float64\n",
      " 6   lng               99163 non-null  float64\n",
      " 7   avg_review        98716 non-null  float64\n",
      " 8   total_spent       98756 non-null  float64\n",
      " 9   avg_spent         98756 non-null  float64\n",
      " 10  avg_installments  98755 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(4)\n",
      "memory usage: 9.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Nombre de paiements moyen réalisés par achat, par client\n",
    "avg_installments = sold_items_df.groupby([\"customer_unique_id\"]).mean(numeric_only=True)\n",
    "avg_installments.rename(columns={\"payment_installments\": \"avg_installments\"}, inplace=True)\n",
    "unique_df = unique_df.merge(how=\"left\", right=avg_installments[\"avg_installments\"], left_on=\"unique_id\", right_index=True)\n",
    "print(unique_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e969679-abc0-4bd4-ab3a-ec7784840f2b",
   "metadata": {},
   "source": [
    "Passons maintenant à la catégorie de produits préférée du client. Ici, on réalise que plusieurs problèmes se posent :\n",
    "- Certains clients n'ont pas une unique catégorie de produits préférée (e.g. pour un client qui a commandé en tout deux articles de catégories différentes)\n",
    "- Ces catégories de produits, actuellement en format texte, devront être converties en nombres pour être exploitables par un modèle de clustering. Une solution serait d'attribuer un index sous la forme d'un nombre entier à chaque catégorie. Cependant, **procéder de cette manière impliquerait une \"proximité\" mathématique entre certaines catégories**. Autrement dit, la catégorie d'index 5 serait considérée comme \"proche\" de la catégorie d'index 6, ce qui serait faux (la catégorie 5 pourrait ne rien avoir en commun avec la catégorie 6 mais être relativement similaire à la catégorie 32, par exemple). \n",
    "\n",
    "Pour ces raisons, on préférera dans un premier temps ne pas exploiter les données concernant la catégorie des produits. On pourra envisager de les exploiter plus tard, si le temps le permet et que des solutions adaptées sont trouvées pour résoudre les deux problèmes ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6421a28e-9bfe-43ff-9291-0c7a5295f518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 118379 entries, 0 to 118378\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   id                  118379 non-null  object \n",
      " 1   unique_id           118379 non-null  object \n",
      " 2   zip                 118379 non-null  int64  \n",
      " 3   city                118379 non-null  object \n",
      " 4   state               118379 non-null  object \n",
      " 5   lat                 118063 non-null  float64\n",
      " 6   lng                 118063 non-null  float64\n",
      " 7   avg_review          117440 non-null  float64\n",
      " 8   total_spent         117694 non-null  float64\n",
      " 9   avg_spent           117694 non-null  float64\n",
      " 10  avg_installments    117691 non-null  float64\n",
      " 11  distance_to_seller  117032 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(4)\n",
      "memory usage: 11.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Ajout de la colonne distance_to_seller\n",
    "# Pour commencer, on code une fonction qui calcule la distance entre \n",
    "# deux points en fonction de leurs coordonnées GPS\n",
    "\n",
    "def get_distance(lat1: float,\n",
    "                long1: float,\n",
    "                lat2: float,\n",
    "                long2: float) -> float:\n",
    "    \"\"\"Renvoit la distance entre deux points (en km)\"\"\"\n",
    "    \n",
    "    return hs.haversine((lat1, long1), (lat2, long2))\n",
    "\n",
    "# On ajoute quatre colonnes à sold_items_df : customer_lat, customer_long, \n",
    "# seller_lat et seller_long\n",
    "\n",
    "sold_items_df = sold_items_df.merge(how=\"left\", right=geolocation_df, left_on=\"customer_zip_code_prefix\", right_on=\"geolocation_zip_code_prefix\")\n",
    "sold_items_df.rename(columns={\"geolocation_lat\": \"customer_lat\", \"geolocation_lng\": \"customer_long\"}, inplace=True)\n",
    "sold_items_df = sold_items_df.merge(how=\"left\", right=geolocation_df, left_on=\"seller_zip_code_prefix\", right_on=\"geolocation_zip_code_prefix\")\n",
    "sold_items_df.rename(columns={\"geolocation_lat\": \"seller_lat\", \"geolocation_lng\": \"seller_long\"}, inplace=True)\n",
    "\n",
    "# On génère ensuite une nouvelle colonne distance_to_seller en se basant sur ces coordonnées, puis on l'ajoute à unique_df\n",
    "sold_items_df[\"distance_to_seller\"] = sold_items_df.apply(lambda row: get_distance(row[\"customer_lat\"],\n",
    "                                                         row[\"customer_long\"],\n",
    "                                                         row[\"seller_lat\"],\n",
    "                                                         row[\"seller_long\"]), axis=1)\n",
    "    \n",
    "\n",
    "unique_df = unique_df.merge(how=\"left\", right=sold_items_df[[\"distance_to_seller\", \"customer_id\"]], left_on=\"id\", right_on=\"customer_id\")\n",
    "unique_df.drop(columns=[\"customer_id\"], inplace=True)\n",
    "print(unique_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e4694-5826-422e-92ac-9567b016fcc1",
   "metadata": {},
   "source": [
    "Nous voilà maintenant avec un unique dataset prêt à l'emploi qui contient uniquement les colonnes qui nous intéressent :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdf46611-3829-4adf-bf14-c7569e06a893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 id                         unique_id    zip  \\\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0  14409   \n",
      "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   9790   \n",
      "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   1151   \n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   8775   \n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066  13056   \n",
      "\n",
      "                    city state        lat        lng  avg_review  total_spent  \\\n",
      "0                 franca    SP -20.509897 -47.397866         4.0       124.99   \n",
      "1  sao bernardo do campo    SP -23.726853 -46.545746         5.0       289.00   \n",
      "2              sao paulo    SP -23.527788 -46.660310         5.0       139.94   \n",
      "3        mogi das cruzes    SP -23.496930 -46.185352         5.0       149.94   \n",
      "4               campinas    SP -22.987222 -47.151073         5.0       230.00   \n",
      "\n",
      "   avg_spent  avg_installments  distance_to_seller  \n",
      "0     124.99               2.0          346.978072  \n",
      "1     289.00               8.0          413.953662  \n",
      "2     139.94               7.0           29.574181  \n",
      "3     149.94               1.0           19.353828  \n",
      "4     230.00               8.0          219.726932  \n"
     ]
    }
   ],
   "source": [
    "print(unique_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca87de02-a134-47ad-998b-008bd4e66cc3",
   "metadata": {},
   "source": [
    "Pour finir, on constate que certaines colonnes contiennent quelques cases vides. Au vu de la faible quantité de données concernée, on préférera simplement supprimer toutes les lignes où il manque des valeurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec6cb77a-d89a-4a16-8123-944270dc5347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 116109 entries, 0 to 118378\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   id                  116109 non-null  object \n",
      " 1   unique_id           116109 non-null  object \n",
      " 2   zip                 116109 non-null  int64  \n",
      " 3   city                116109 non-null  object \n",
      " 4   state               116109 non-null  object \n",
      " 5   lat                 116109 non-null  float64\n",
      " 6   lng                 116109 non-null  float64\n",
      " 7   avg_review          116109 non-null  float64\n",
      " 8   total_spent         116109 non-null  float64\n",
      " 9   avg_spent           116109 non-null  float64\n",
      " 10  avg_installments    116109 non-null  float64\n",
      " 11  distance_to_seller  116109 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(4)\n",
      "memory usage: 11.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "unique_df.dropna(inplace=True)\n",
    "print(unique_df.info())\n",
    "pickle.dump(unique_df, open(\"clean_data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6036504-f45f-4589-9466-e2b6f370be2c",
   "metadata": {},
   "source": [
    "## Visualisation des données et analyses statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d71a4a8-ba02-449f-88b7-8ae586f64536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
